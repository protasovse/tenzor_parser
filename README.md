Выбор полезного содержимого страницы со статьёй сайта
-----------------------------------------------------

Перейдите туда, где будет находиться ваш проект

```cd ~```

Клонируем репозиторий https://github.com/protasovse/tenzor_parser

```git clone https://github.com/protasovse/tenzor_parser.git```


Виртуальная среда
-----------------

Если у вас нет virtualenv, вам нужно его установить. Это позволит вам иметь отдельные
установки программного обеспечения для каждого проекта:

```sudo pip install virtualenv```

Теперь начнём:

```
cd tenzor_parser
virtualenv venv
source venv/bin/activate
```

Теперь установите все, что нам нужно:

```pip install -r requirements.txt```

И проверить, что у нас есть Django:

```python -c "import django; print(django.get_version())"```

Теперь через командную строку добавим URL страницы, с которой нужно взять полезное содержимое:

```python manage.py parse -u https://lenta.ru/news/2018/12/25/podarochek/```

Теперь, что бы проверить результат, запустим сервер:

```python manage.py runserver```

Переходим в браузере по адресу:

```http://127.0.0.1:8000/admin```

Введём логин и пароль:

```
admin
gF7Lg#dyTbn
```

Перходим в приложении PAGES модель «Содержание», читаем только что добавленную статью!

Так же файлы с добавленными статьями дублируются в папке media проекта.

В админке Вы можете увидеть другие страницы, которые тестировал с помощью этого кода,
иам же — результаты сбора полезной информации.

При создании проекта использовалось: Python3, Django 1.11.17, SQLLite.
Для парсинга html содержимого страницы — BeautifulSoup
Для приведения текста к «красивому» виду — Markdownify

На большинстве сайтов заголовок и весь текст статьи находится в слое, который помечен
схожими атрибутами. Так же заголовок есть смысл проверять в теге h1 страницы, либо теге
title раздела head. Я проанализировал несколько десятков новостных порталов и выписал
атрибуты, которыми помечают обычно контейнер с текстом статьи. Их оформил в виде «правил»
(переменные TITLE_RULES_LIST и TEXT_RULES_LIST модуля pages/parser.py)

Для некоторых сайтов правила находятся в таблице Rules проекта. Если нам необходимо спарсить
текст неизвестного сайто, то применяются общие правила.

Для дальнейшего улучшения качества парсинга, нужно собрать все правила с сайтов с которых с
большей вероятностью мы будем брать информацию. Так же подумать над постпарсингом html
кода статьи, потому что некоторые сайты помечают абзацы тегом p, некоторые нет. И в 
теле статьи, часто, много «грязи».



